{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-08-11T07:59:56.719857Z","iopub.status.busy":"2023-08-11T07:59:56.719391Z","iopub.status.idle":"2023-08-11T07:59:57.821378Z","shell.execute_reply":"2023-08-11T07:59:57.820137Z","shell.execute_reply.started":"2023-08-11T07:59:56.719806Z"}},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","import torch.utils.data as data\n","import numpy as np\n","from torch import nn, optim"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!rmdir -p /kaggle/working/results"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!mkdir -p /kaggle/working/results"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["textPath = 'wonderland.txt'\n","\n","text = open(textPath, 'r', encoding='utf-8').read()\n","text = text.lower()\n","vocab = sorted(set(text))\n","char_to_int = dict((c, i) for i, c in enumerate(vocab))\n","\n","n_chars = len(text)\n","n_vocab = len(vocab)\n","print('n_chars:', n_chars, 'n_vocab:', n_vocab)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["seq_length = 100\n","\n","dataX = []\n","dataY = []\n","\n","for i in range(0, n_chars - seq_length, 1):\n","    seq_in = text[i:i + seq_length]\n","    seq_out = text[i + seq_length]\n","\n","    dataX.append([char_to_int[char] for char in seq_in])\n","    dataY.append(char_to_int[seq_out])\n","\n","n_patterns = len(dataX) \n","print(n_patterns)  "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X = torch.tensor(dataX).long()\n","y = torch.tensor(dataY).long()\n","\n","print(X.shape)\n","print(y.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class CharModel(nn.Module):\n","\n","    def __init__(self, embed_size, hidden_size, n_vocab, num_layers=1, Batch_first=True):\n","        super().__init__()\n","        self.embed_size = embed_size\n","        self.hidden_size = hidden_size\n","        self.n_vocab = n_vocab\n","        self.num_layers = num_layers\n","        self.batch_first = Batch_first\n","\n","        self.embed = nn.Embedding(self.n_vocab, self.embed_size)\n","        self.lstm = nn.LSTM(input_size=self.embed_size, hidden_size=self.hidden_size, num_layers=self.num_layers, batch_first=self.batch_first, dropout=0.2)\n","        self.dropout = nn.Dropout(0.2)\n","        self.linear = nn.Linear(self.hidden_size, self.n_vocab)\n","\n","    def forward(self, x, h_0, c_0):\n","        out = self.embed(x)\n","        out, (h_n, c_n) = self.lstm(out, (h_0, c_0))\n","        # take only the last output\n","        out = out[:, -1, :] \n","        # produce output\n","        out = self.linear(self.dropout(out))\n","        \n","        return out\n","    \n","    def init_hidden(self, batch_size):\n","        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n","        cell = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n","        return hidden, cell"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Train"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["n_epochs = 10\n","batch_size = 1\n","embed_size = 10\n","hidden_size = 256\n","num_layers= 1\n","\n","model = CharModel(embed_size=embed_size, hidden_size=hidden_size, n_vocab=n_vocab, num_layers=num_layers).to(device)\n","\n","optimizer = optim.Adam(model.parameters())\n","loss_fn = nn.CrossEntropyLoss(reduction=\"sum\")\n","loader = data.DataLoader(data.TensorDataset(X, y), shuffle=True, batch_size=batch_size)\n"," \n","best_model = None\n","best_loss = np.inf\n","\n","for epoch in range(n_epochs):\n","    model.train()\n","    \n","    for X_batch, y_batch in loader:\n","        h_0, c_0 = model.init_hidden(batch_size=batch_size)\n","        h_0 = h_0.to(device)\n","        c_0 = c_0.to(device)\n","        X_batch = X_batch.to(device)\n","        y_pred = model(X_batch, h_0, c_0)\n","        loss = loss_fn(y_pred, y_batch.to(device))\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","    # Validation\n","    model.eval()\n","    loss = 0\n","\n","    with torch.no_grad():\n","\n","        for X_batch, y_batch in loader:\n","            y_pred = model(X_batch.to(device), h_0, c_0)\n","            loss += loss_fn(y_pred, y_batch.to(device))\n","\n","        if loss < best_loss:\n","            best_loss = loss\n","            best_model = model.state_dict()\n","        print(\"Epoch %d: Cross-entropy: %.4f\" % (epoch, loss))\n"," \n","torch.save([best_model, char_to_int], \"single-char.pth\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Generate"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["best_model, char_to_int = torch.load(\"single-char.pth\")\n","n_vocab = len(char_to_int)\n","int_to_char = dict((i, c) for c, i in char_to_int.items())\n","\n","embed_size = 10\n","hidden_size = 256\n","num_layers= 1\n"," \n","# reload the model\n","class CharModel(nn.Module):\n","\n","    def __init__(self, embed_size, hidden_size, n_vocab, num_layers=1, Batch_first=True):\n","        super().__init__()\n","        self.embed_size = embed_size\n","        self.hidden_size = hidden_size\n","        self.n_vocab = n_vocab\n","        self.num_layers = num_layers\n","        self.batch_first = Batch_first\n","\n","        self.embed = nn.Embedding(self.n_vocab, self.embed_size)\n","        self.lstm = nn.LSTM(input_size=self.embed_size, hidden_size=self.hidden_size, num_layers=self.num_layers, batch_first=self.batch_first, dropout=0.2)\n","        self.dropout = nn.Dropout(0.2)\n","        self.linear = nn.Linear(self.hidden_size, self.n_vocab)\n","\n","    def forward(self, x, h_0, c_0):\n","        out = self.embed(x)\n","        out, (h_n, c_n) = self.lstm(out, (h_0, c_0))\n","        # take only the last output\n","        out = out[:, -1, :] \n","        # produce output\n","        out = self.linear(self.dropout(out))\n","        \n","        return out\n","    \n","    def init_hidden(self, batch_size):\n","        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n","        cell = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n","        return hidden, cell\n","    \n","model = CharModel(embed_size, hidden_size, n_vocab, num_layers=1, Batch_first=True).to(device)\n","model.load_state_dict(best_model)\n"," \n","# randomly generate a prompt\n","filename = \"wonderland.txt\"\n","seq_length = 100\n","raw_text = open(filename, 'r', encoding='utf-8').read()\n","raw_text = raw_text.lower()\n","start = np.random.randint(0, len(raw_text)-seq_length)\n","prompt = raw_text[start:start+seq_length]\n","pattern = [char_to_int[c] for c in prompt]\n"," \n","model.eval()\n","print('Prompt: \"%s\"' % prompt)\n","\n","with torch.no_grad():\n","    \n","    for i in range(500):\n","        # format input array of int into PyTorch tensor\n","        h_0, c_0 = model.init_hidden(batch_size=batch_size)\n","        h_0 = h_0.to(device)\n","        c_0 = c_0.to(device)\n","        x = np.reshape(pattern, (1, len(pattern)))\n","        x = torch.tensor(x).long().to(device)\n","        # generate logits as output from the model\n","        prediction = model(x, h_0, c_0)\n","        # convert logits into one character\n","        index = int(prediction.argmax())\n","        result = int_to_char[index]\n","        print(result, end=\"\")\n","        # append the new character into the prompt for the next iteration\n","        pattern.append(index)\n","        pattern = pattern[1:]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
