{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "from torch import nn, optim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_chars: 144805 n_vocab: 50\n"
     ]
    }
   ],
   "source": [
    "textPath = 'wonderland.txt'\n",
    "\n",
    "text = open(textPath, 'r', encoding='utf-8').read()\n",
    "text = text.lower()\n",
    "vocab = sorted(set(text))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(vocab))\n",
    "\n",
    "n_chars = len(text)\n",
    "n_vocab = len(vocab)\n",
    "print('n_chars:', n_chars, 'n_vocab:', n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144705\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "\n",
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = text[i:i + seq_length]\n",
    "    seq_out = text[i + seq_length]\n",
    "\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "\n",
    "n_patterns = len(dataX) \n",
    "print(n_patterns)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([144705, 100])\n",
      "torch.Size([144705])\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor(dataX).long()\n",
    "y = torch.tensor(dataY).long()\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharModel(nn.Module):\n",
    "\n",
    "    def __init__(self, embed_size, hidden_size, n_vocab, num_layers=1, Batch_first=True):\n",
    "        super().__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_vocab = n_vocab\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = Batch_first\n",
    "\n",
    "        self.embed = nn.Embedding(self.n_vocab, self.embed_size)\n",
    "        self.lstm = nn.LSTM(input_size=self.embed_size, hidden_size=self.hidden_size, num_layers=self.num_layers, batch_first=self.batch_first, dropout=0.2)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.linear = nn.Linear(self.hidden_size, self.n_vocab)\n",
    "\n",
    "    def forward(self, x, h_0, c_0):\n",
    "        out = self.embed(x)\n",
    "        out, (h_n, c_n) = self.lstm(out, (h_0, c_0))\n",
    "        # take only the last output\n",
    "        out = out[:, -1, :] \n",
    "        # produce output\n",
    "        out = self.linear(self.dropout(out))\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        cell = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        return hidden, cell"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\RNN\\Course_assignment_pytorch\\RNNCourse\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Cross-entropy: 217275.6250\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m     35\u001b[0m     \u001b[39mfor\u001b[39;00m X_batch, y_batch \u001b[39min\u001b[39;00m loader:\n\u001b[1;32m---> 36\u001b[0m         y_pred \u001b[39m=\u001b[39m model(X_batch\u001b[39m.\u001b[39;49mto(device), h_0, c_0)\n\u001b[0;32m     37\u001b[0m         loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss_fn(y_pred, y_batch\u001b[39m.\u001b[39mto(device))\n\u001b[0;32m     39\u001b[0m     \u001b[39mif\u001b[39;00m loss \u001b[39m<\u001b[39m best_loss:\n",
      "File \u001b[1;32mf:\\RNN\\Course_assignment_pytorch\\RNNCourse\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[13], line 18\u001b[0m, in \u001b[0;36mCharModel.forward\u001b[1;34m(self, x, h_0, c_0)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, h_0, c_0):\n\u001b[0;32m     17\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed(x)\n\u001b[1;32m---> 18\u001b[0m     out, (h_n, c_n) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(out, (h_0, c_0))\n\u001b[0;32m     19\u001b[0m     \u001b[39m# take only the last output\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     out \u001b[39m=\u001b[39m out[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :] \n",
      "File \u001b[1;32mf:\\RNN\\Course_assignment_pytorch\\RNNCourse\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mf:\\RNN\\Course_assignment_pytorch\\RNNCourse\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:812\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    811\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 812\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[0;32m    813\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[0;32m    814\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    815\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[0;32m    816\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 1\n",
    "embed_size = 10\n",
    "hidden_size = 256\n",
    "num_layers= 1\n",
    "\n",
    "model = CharModel(embed_size=embed_size, hidden_size=hidden_size, n_vocab=n_vocab, num_layers=num_layers).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "loader = data.DataLoader(data.TensorDataset(X, y), shuffle=True, batch_size=batch_size)\n",
    " \n",
    "best_model = None\n",
    "best_loss = np.inf\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    for X_batch, y_batch in loader:\n",
    "        h_0, c_0 = model.init_hidden(batch_size=batch_size)\n",
    "        h_0 = h_0.to(device)\n",
    "        c_0 = c_0.to(device)\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_pred = model(X_batch, h_0, c_0)\n",
    "        print('pred', y_pred.shape)\n",
    "        print('org', y_batch.shape)\n",
    "        loss = loss_fn(y_pred, y_batch.to(device))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for X_batch, y_batch in loader:\n",
    "            y_pred = model(X_batch.to(device), h_0, c_0)\n",
    "            loss += loss_fn(y_pred, y_batch.to(device))\n",
    "\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_model = model.state_dict()\n",
    "        print(\"Epoch %d: Cross-entropy: %.4f\" % (epoch, loss))\n",
    " \n",
    "torch.save([best_model, char_to_int], \"single-char.pth\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: \"ange them—” when she\n",
      "was a little startled by seeing the cheshire cat sitting on a bough of\n",
      "a tree a\"\n",
      " little to the caterpillar the caterpillar the caterpillar the caterpillar the caterpillar the caterpillar the caterpillar the caterpillar the caterpillar the caterpillar the caterpillar the caterpillar the caterpillar the caterpillar the caterpillar the caterpillar the caterpillar the caterpillar the caterpillar the caterpillar the caterpillar the caterpillar the caterpillar the caterpillar the caterpillar the caterpillar the caterpillar the caterpillar the caterpillar the caterpillar the cater"
     ]
    }
   ],
   "source": [
    "best_model, char_to_int = torch.load(\"/kaggle/working/results/single-char.pth\")\n",
    "n_vocab = len(char_to_int)\n",
    "int_to_char = dict((i, c) for c, i in char_to_int.items())\n",
    "\n",
    "embed_size = 10\n",
    "hidden_size = 256\n",
    "num_layers= 1\n",
    " \n",
    "# reload the model\n",
    "class CharModel(nn.Module):\n",
    "\n",
    "    def __init__(self, embed_size, hidden_size, n_vocab, num_layers=1, Batch_first=True):\n",
    "        super().__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_vocab = n_vocab\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = Batch_first\n",
    "\n",
    "        self.embed = nn.Embedding(self.n_vocab, self.embed_size)\n",
    "        self.lstm = nn.LSTM(input_size=self.embed_size, hidden_size=self.hidden_size, num_layers=self.num_layers, batch_first=self.batch_first, dropout=0.2)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.linear = nn.Linear(self.hidden_size, self.n_vocab)\n",
    "\n",
    "    def forward(self, x, h_0, c_0):\n",
    "        out = self.embed(x)\n",
    "        out, (h_n, c_n) = self.lstm(out, (h_0, c_0))\n",
    "        # take only the last output\n",
    "        out = out[:, -1, :] \n",
    "        # produce output\n",
    "        out = self.linear(self.dropout(out))\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        cell = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        return hidden, cell\n",
    "    \n",
    "model = CharModel(embed_size, hidden_size, n_vocab, num_layers=1, Batch_first=True).to(device)\n",
    "model.load_state_dict(best_model)\n",
    " \n",
    "# randomly generate a prompt\n",
    "filename = \"/kaggle/input/textgeneration/wonderland.txt\"\n",
    "seq_length = 100\n",
    "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
    "raw_text = raw_text.lower()\n",
    "start = np.random.randint(0, len(raw_text)-seq_length)\n",
    "prompt = raw_text[start:start+seq_length]\n",
    "pattern = [char_to_int[c] for c in prompt]\n",
    " \n",
    "model.eval()\n",
    "print('Prompt: \"%s\"' % prompt)\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i in range(500):\n",
    "        # format input array of int into PyTorch tensor\n",
    "        h_0, c_0 = model.init_hidden(batch_size=batch_size)\n",
    "        h_0 = h_0.to(device)\n",
    "        c_0 = c_0.to(device)\n",
    "        x = np.reshape(pattern, (1, len(pattern)))\n",
    "        x = torch.tensor(x).long().to(device)\n",
    "        # generate logits as output from the model\n",
    "        prediction = model(x, h_0, c_0)\n",
    "        # convert logits into one character\n",
    "        index = int(prediction.argmax())\n",
    "        result = int_to_char[index]\n",
    "        print(result, end=\"\")\n",
    "        # append the new character into the prompt for the next iteration\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RNNCourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
